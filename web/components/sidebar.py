"""
ä¾§è¾¹æ ç»„ä»¶
"""

import streamlit as st
import os

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""
    
    with st.sidebar:
        st.header("ğŸ”§ ç³»ç»Ÿé…ç½®")
        
        # APIå¯†é’¥çŠ¶æ€
        st.subheader("ğŸ”‘ APIå¯†é’¥çŠ¶æ€")
        
        # æ£€æŸ¥å„ä¸ªAPIå¯†é’¥
        google_key = os.getenv("GOOGLE_API_KEY")
        finnhub_key = os.getenv("FINNHUB_API_KEY")
        dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        
        # Google AI (ä¸»è¦)
        if google_key:
            st.success(f"âœ… Google AI: {google_key[:12]}...")
        else:
            st.error("âŒ Google AI: æœªé…ç½®")
        
        # é‡‘èæ•°æ®
        if finnhub_key:
            st.success(f"âœ… é‡‘èæ•°æ®: {finnhub_key[:12]}...")
        else:
            st.error("âŒ é‡‘èæ•°æ®: æœªé…ç½®")
        
        # å…¶ä»–å¯é€‰API
        if dashscope_key:
            st.info(f"â„¹ï¸ é˜¿é‡Œç™¾ç‚¼: {dashscope_key[:12]}... (å¤‡ç”¨)")
        
        if openai_key:
            st.info(f"â„¹ï¸ OpenAI: {openai_key[:12]}... (å¤‡ç”¨)")
        
        st.markdown("---")
        
        # AIæ¨¡å‹ä¿¡æ¯ (åªæ˜¾ç¤ºï¼Œä¸å…è®¸é€‰æ‹©)
        st.subheader("ğŸ§  AIæ¨¡å‹é…ç½®")
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        llm_provider = os.getenv("LLM_PROVIDER", "google")
        deep_think_model = os.getenv("DEEP_THINK_MODEL", "gemini-2.0-flash")
        quick_think_model = os.getenv("QUICK_THINK_MODEL", "gemini-1.5-flash")
        
        # æ˜¾ç¤ºå½“å‰é…ç½®
        st.info(f"""
        **å½“å‰é…ç½®:**
        - æä¾›å•†: {llm_provider.upper()}
        - æ·±åº¦åˆ†ææ¨¡å‹: {deep_think_model}
        - å¿«é€Ÿåˆ†ææ¨¡å‹: {quick_think_model}
        
        ğŸ’¡ æ¨¡å‹é…ç½®é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­ä¿®æ”¹
        """)
        
        # é«˜çº§è®¾ç½®
        with st.expander("âš™ï¸ é«˜çº§è®¾ç½®"):
            enable_memory = st.checkbox(
                "å¯ç”¨è®°å¿†åŠŸèƒ½",
                value=False,
                help="å¯ç”¨æ™ºèƒ½ä½“è®°å¿†åŠŸèƒ½ï¼ˆå¯èƒ½å½±å“æ€§èƒ½ï¼‰"
            )
            
            enable_debug = st.checkbox(
                "è°ƒè¯•æ¨¡å¼",
                value=False,
                help="å¯ç”¨è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯è¾“å‡º"
            )
            
            max_tokens = st.slider(
                "æœ€å¤§è¾“å‡ºé•¿åº¦",
                min_value=1000,
                max_value=8000,
                value=4000,
                step=500,
                help="AIæ¨¡å‹çš„æœ€å¤§è¾“å‡ºtokenæ•°é‡"
            )
        
        st.markdown("---")
        
        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
        
        st.info(f"""
        **ç‰ˆæœ¬**: 1.0.0
        **æ¡†æ¶**: Streamlit + LangGraph
        **AIæ¨¡å‹**: {llm_provider.upper()} ({deep_think_model})
        **æ•°æ®æº**: FinnHub API
        """)
        
        # å¸®åŠ©é“¾æ¥
        st.subheader("ğŸ“š å¸®åŠ©èµ„æº")
        
        st.markdown("""
        - [ğŸ“– ä½¿ç”¨æ–‡æ¡£](https://github.com/TauricResearch/TradingAgents)
        - [ğŸ› é—®é¢˜åé¦ˆ](https://github.com/TauricResearch/TradingAgents/issues)
        - [ğŸ’¬ è®¨è®ºç¤¾åŒº](https://github.com/TauricResearch/TradingAgents/discussions)
        - [ğŸ”§ APIå¯†é’¥é…ç½®](../docs/security/api_keys_security.md)
        """)
    
    # è¿”å›é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    return {
        'llm_provider': llm_provider,
        'llm_model': deep_think_model,  # ä½¿ç”¨æ·±åº¦åˆ†ææ¨¡å‹ä½œä¸ºä¸»æ¨¡å‹
        'enable_memory': enable_memory,
        'enable_debug': enable_debug,
        'max_tokens': max_tokens
    }
